import os
import torch
import uuid
import time
import asyncio
import numpy as np
from threading import Lock
from typing import Optional, Dict, List
from fastapi import FastAPI, HTTPException, status, Depends
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel, Field, field_validator, ValidationError
from diffusers.utils import export_to_video, load_image
from diffusers import AutoencoderKLWan, WanImageToVideoPipeline
from diffusers.schedulers.scheduling_unipc_multistep import UniPCMultistepScheduler
from transformers import CLIPVisionModel
from PIL import Image
import requests
from io import BytesIO
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
from contextlib import asynccontextmanager
from requests.exceptions import RequestException

# åˆ›å»ºå­˜å‚¨ç›®å½•
os.makedirs("generated_videos", exist_ok=True)
os.makedirs("temp_images", exist_ok=True)

# ======================
# ç”Ÿå‘½å‘¨æœŸç®¡ç†
# ======================
@asynccontextmanager
async def lifespan(app: FastAPI):
    """èµ„æºç®¡ç†å™¨"""
    try:
        # åˆå§‹åŒ–è®¤è¯ç³»ç»Ÿ
        app.state.valid_api_keys = {
            "å¯†é’¥"
        }

        # åˆå§‹åŒ–æ¨¡å‹
        model_id = "./Wan2.1-I2V-14B-480P-Diffusers"
      
        # åŠ è½½å›¾åƒç¼–ç å™¨
        image_encoder = CLIPVisionModel.from_pretrained(
            model_id,
            subfolder="image_encoder",
            torch_dtype=torch.float32
        )
      
        # åŠ è½½VAE
        vae = AutoencoderKLWan.from_pretrained(
            model_id,
            subfolder="vae",
            torch_dtype=torch.float32
        )
      
        # é…ç½®è°ƒåº¦å™¨
        scheduler = UniPCMultistepScheduler(
            prediction_type='flow_prediction',
            use_flow_sigmas=True,
            num_train_timesteps=1000,
            flow_shift=3.0
        )
      
        # åˆ›å»ºç®¡é“
        app.state.pipe = WanImageToVideoPipeline.from_pretrained(
            model_id,
            vae=vae,
            image_encoder=image_encoder,
            torch_dtype=torch.bfloat16
        ).to("cuda")
        app.state.pipe.scheduler = scheduler

        # åˆå§‹åŒ–ä»»åŠ¡ç³»ç»Ÿ
        app.state.tasks: Dict[str, dict] = {}
        app.state.pending_queue: List[str] = []
        app.state.model_lock = Lock()
        app.state.task_lock = Lock()
        app.state.base_url = "ipåœ°å€+ç«¯å£"
        app.state.semaphore = asyncio.Semaphore(2)  # å¹¶å‘é™åˆ¶

        # å¯åŠ¨åå°å¤„ç†å™¨
        asyncio.create_task(task_processor())

        print("âœ… ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
        yield

    finally:
        # èµ„æºæ¸…ç†
        if hasattr(app.state, 'pipe'):
            del app.state.pipe
            torch.cuda.empty_cache()
            print("â™»ï¸ èµ„æºå·²é‡Šæ”¾")

# ======================
# FastAPIåº”ç”¨
# ======================
app = FastAPI(lifespan=lifespan)
app.mount("/videos", StaticFiles(directory="generated_videos"), name="videos")
# è®¤è¯æ¨¡å—
security = HTTPBearer(auto_error=False)

# ======================
# æ•°æ®æ¨¡å‹--æŸ¥è¯¢å‚æ•°æ¨¡å‹
# ======================
class VideoSubmitRequest(BaseModel):
    model: str = Field(
        default="Wan2.1-I2V-14B-480P",
        description="æ¨¡å‹ç‰ˆæœ¬"
    )
    prompt: str = Field(
        ...,
        min_length=10,
        max_length=500,
        description="è§†é¢‘æè¿°æç¤ºè¯ï¼Œ10-500ä¸ªå­—ç¬¦"
    )
    image_url: str = Field(
        ...,
        description="è¾“å…¥å›¾åƒURLï¼Œéœ€æ”¯æŒHTTP/HTTPSåè®®"
    )
    image_size: str = Field(
        default="auto",
        description="è¾“å‡ºåˆ†è¾¨ç‡ï¼Œæ ¼å¼ï¼šå®½xé«˜ æˆ– autoï¼ˆè‡ªåŠ¨è®¡ç®—ï¼‰"
    )
    negative_prompt: Optional[str] = Field(
        default=None,
        max_length=500,
        description="æ’é™¤ä¸éœ€è¦çš„å†…å®¹"
    )
    seed: Optional[int] = Field(
        default=None,
        ge=0,
        le=2147483647,
        description="éšæœºæ•°ç§å­ï¼ŒèŒƒå›´0-2147483647"
    )
    num_frames: int = Field(
        default=81,
        ge=24,
        le=120,
        description="è§†é¢‘å¸§æ•°ï¼Œ24-89å¸§"
    )
    guidance_scale: float = Field(
        default=3.0,
        ge=1.0,
        le=20.0,
        description="å¼•å¯¼ç³»æ•°ï¼Œ1.0-20.0"
    )
    infer_steps: int = Field(
        default=30,
        ge=20,
        le=100,
        description="æ¨ç†æ­¥æ•°ï¼Œ20-100æ­¥"
    )

    @field_validator('image_size')
    def validate_image_size(cls, v):
        allowed_sizes = {"480x832", "832x480", "auto"}
        if v not in allowed_sizes:
            raise ValueError(f"æ”¯æŒçš„åˆ†è¾¨ç‡: {', '.join(allowed_sizes)}")
        return v

class VideoStatusRequest(BaseModel):
    requestId: str = Field(
        ...,
        min_length=32,
        max_length=32,
        description="32ä½ä»»åŠ¡ID"
    )

class VideoStatusResponse(BaseModel):
    status: str = Field(..., description="ä»»åŠ¡çŠ¶æ€: Succeed, InQueue, InProgress, Failed,Cancelled")
    reason: Optional[str] = Field(None, description="å¤±è´¥åŸå› ")
    results: Optional[dict] = Field(None, description="ç”Ÿæˆç»“æœ")
    queue_position: Optional[int] = Field(None, description="é˜Ÿåˆ—ä½ç½®")

class VideoCancelRequest(BaseModel):
    requestId: str = Field(
        ...,
        min_length=32,
        max_length=32,
        description="32ä½ä»»åŠ¡ID"
    )

# ======================
# æ ¸å¿ƒé€»è¾‘
# ======================
async def verify_auth(credentials: HTTPAuthorizationCredentials = Depends(security)):
    """ç»Ÿä¸€è®¤è¯éªŒè¯"""
    if not credentials:
        raise HTTPException(
            status_code=401,
            detail={"status": "Failed", "reason": "ç¼ºå°‘è®¤è¯å¤´"},
            headers={"WWW-Authenticate": "Bearer"}
        )
    if credentials.scheme != "Bearer":
        raise HTTPException(
            status_code=401,
            detail={"status": "Failed", "reason": "æ— æ•ˆçš„è®¤è¯æ–¹æ¡ˆ"},
            headers={"WWW-Authenticate": "Bearer"}
        )
    if credentials.credentials not in app.state.valid_api_keys:
        raise HTTPException(
            status_code=401,
            detail={"status": "Failed", "reason": "æ— æ•ˆçš„APIå¯†é’¥"},
            headers={"WWW-Authenticate": "Bearer"}
        )
    return True

async def task_processor():
    """ä»»åŠ¡å¤„ç†å™¨"""
    while True:
        async with app.state.semaphore:
            task_id = await get_next_task()
            if task_id:
                await process_task(task_id)
            else:
                await asyncio.sleep(0.5)

async def get_next_task():
    """è·å–ä¸‹ä¸€ä¸ªä»»åŠ¡"""
    with app.state.task_lock:
        return app.state.pending_queue.pop(0) if app.state.pending_queue else None

async def process_task(task_id: str):
    """å¤„ç†å•ä¸ªä»»åŠ¡"""
    task = app.state.tasks.get(task_id)
    if not task:
        return

    try:
        # æ›´æ–°ä»»åŠ¡çŠ¶æ€
        task['status'] = 'InProgress'
        task['started_at'] = int(time.time())
        print(task['request'].image_url)
        # ä¸‹è½½è¾“å…¥å›¾åƒ
        image = await download_image(task['request'].image_url)
        image_path = f"temp_images/{task_id}.jpg"
        image.save(image_path)

        # ç”Ÿæˆè§†é¢‘
        video_path = await generate_video(task['request'], task_id, image)
      
        # ç”Ÿæˆä¸‹è½½é“¾æ¥
        download_url = f"{app.state.base_url}/videos/{os.path.basename(video_path)}"
      
        # æ›´æ–°ä»»åŠ¡çŠ¶æ€
        task.update({
            'status': 'Succeed',
            'download_url': download_url,
            'completed_at': int(time.time())
        })
      
        # å®‰æ’æ¸…ç†
        asyncio.create_task(cleanup_files([image_path, video_path]))
    except Exception as e:
        handle_task_error(task, e)

def handle_task_error(task: dict, error: Exception):
    """é”™è¯¯å¤„ç†ï¼ˆåŒ…å«è¯¦ç»†é”™è¯¯ä¿¡æ¯ï¼‰"""
    error_msg = str(error)
  
    # 1. æ˜¾å­˜ä¸è¶³é”™è¯¯
    if isinstance(error, torch.cuda.OutOfMemoryError):
        error_msg = "æ˜¾å­˜ä¸è¶³ï¼Œè¯·é™ä½åˆ†è¾¨ç‡"
      
    # 2. ç½‘ç»œè¯·æ±‚ç›¸å…³é”™è¯¯
    elif isinstance(error, (RequestException, HTTPException)):
        # ä»å¼‚å¸¸ä¸­æå–å…·ä½“ä¿¡æ¯
        if isinstance(error, HTTPException):
            # å¦‚æœæ˜¯ HTTPExceptionï¼Œè·å–å…¶ detail å­—æ®µ
            error_detail = getattr(error, "detail", "")
            error_msg = f"å›¾åƒä¸‹è½½å¤±è´¥: {error_detail}"
          
        elif isinstance(error, Timeout):
            error_msg = "å›¾åƒä¸‹è½½è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œ"
          
        elif isinstance(error, ConnectionError):
            error_msg = "æ— æ³•è¿æ¥åˆ°æœåŠ¡å™¨ï¼Œè¯·æ£€æŸ¥ URL"
          
        elif isinstance(error, HTTPError):
            # requests çš„ HTTPErrorï¼ˆä¾‹å¦‚ 4xx/5xx çŠ¶æ€ç ï¼‰
            status_code = error.response.status_code
            error_msg = f"æœåŠ¡å™¨è¿”å›é”™è¯¯çŠ¶æ€ç : {status_code}"
          
        else:
            # å…¶ä»– RequestException é”™è¯¯
            error_msg = f"å›¾åƒä¸‹è½½å¤±è´¥: {str(error)}"
  
    # 3. å…¶ä»–æœªçŸ¥é”™è¯¯
    else:
        error_msg = f"æœªçŸ¥é”™è¯¯: {str(error)}"
  
    # æ›´æ–°ä»»åŠ¡çŠ¶æ€
    task.update({
        'status': 'Failed',
        'reason': error_msg,
        'completed_at': int(time.time())
    })
# ======================
# è§†é¢‘ç”Ÿæˆé€»è¾‘
# ======================
async def download_image(url: str) -> Image.Image:
    """å¼‚æ­¥ä¸‹è½½å›¾åƒï¼ˆåŒ…å«è¯¦ç»†é”™è¯¯ä¿¡æ¯ï¼‰"""
    loop = asyncio.get_event_loop()
    try:
        response = await loop.run_in_executor(
            None, 
            lambda: requests.get(url)  # å°† timeout ä¼ é€’ç»™ requests.get
        )
      
        # å¦‚æœçŠ¶æ€ç é 200ï¼Œä¸»åŠ¨æŠ›å‡º HTTPException
        if response.status_code != 200:
            raise HTTPException(
                status_code=response.status_code,
                detail=f"æœåŠ¡å™¨è¿”å›çŠ¶æ€ç  {response.status_code}"
            )
          
        return Image.open(BytesIO(response.content)).convert("RGB")
      
    except RequestException as e:
        # å°†åŸå§‹ requests é”™è¯¯ä¿¡æ¯æŠ›å‡º
        raise HTTPException(
            status_code=500,
            detail=f"è¯·æ±‚å¤±è´¥: {str(e)}"
        )
async def generate_video(request: VideoSubmitRequest, task_id: str, image: Image.Image):
    """å¼‚æ­¥ç”Ÿæˆå…¥å£"""
    loop = asyncio.get_event_loop()
    return await loop.run_in_executor(
        None,
        sync_generate_video,
        request,
        task_id,
        image
    )

def sync_generate_video(request: VideoSubmitRequest, task_id: str, image: Image.Image):
    """åŒæ­¥ç”Ÿæˆæ ¸å¿ƒ"""
    with app.state.model_lock:
        try:
            # è§£æåˆ†è¾¨ç‡
            mod_value = 16  # æ¨¡å‹è¦æ±‚çš„æ¨¡æ•°
            print(request.image_size)
            print('--------------------------------')
            if request.image_size == "auto":
                # åŸç‰ˆè‡ªåŠ¨è®¡ç®—é€»è¾‘
                aspect_ratio = image.height / image.width
                print(image.height,image.width)
                max_area = 399360  # æ¨¡å‹åŸºç¡€åˆ†è¾¨ç‡
              
                # è®¡ç®—ç†æƒ³å°ºå¯¸
                height = round(np.sqrt(max_area * aspect_ratio)) 
                width = round(np.sqrt(max_area / aspect_ratio))
              
                # åº”ç”¨æ¨¡æ•°è°ƒæ•´
                height = height // mod_value * mod_value
                width = width // mod_value * mod_value
                resized_image = image.resize((width, height))
            else:
                width_str, height_str = request.image_size.split('x')
                width = int(width_str)
                height = int(height_str)
                mod_value = 16          
                # è°ƒæ•´å›¾åƒå°ºå¯¸
                resized_image = image.resize((width, height))
            
              
            # è®¾ç½®éšæœºç§å­
            generator = None
            # ä¿®æ”¹ç‚¹1: ä½¿ç”¨å±æ€§è®¿é—®seed
            if request.seed is not None:
                generator = torch.Generator(device="cuda")
                generator.manual_seed(request.seed)  # ä¿®æ”¹ç‚¹2
                print(f"ğŸ”® ä½¿ç”¨éšæœºç§å­: {request.seed}")
            print(resized_image)
            print(height,width)

            # æ‰§è¡Œæ¨ç†
            output = app.state.pipe(
                image=resized_image,
                prompt=request.prompt,
                negative_prompt=request.negative_prompt,
                height=height,
                width=width,
                num_frames=request.num_frames,
                guidance_scale=request.guidance_scale,
                num_inference_steps=request.infer_steps,
                generator=generator
            ).frames[0]

            # å¯¼å‡ºè§†é¢‘
            video_id = uuid.uuid4().hex
            output_path = f"generated_videos/{video_id}.mp4"
            export_to_video(output, output_path, fps=16)
            return output_path
        except Exception as e:
            raise RuntimeError(f"è§†é¢‘ç”Ÿæˆå¤±è´¥: {str(e)}") from e

# ======================
# APIç«¯ç‚¹
# ======================
@app.post("/video/submit",
          response_model=dict,
          status_code=status.HTTP_202_ACCEPTED,
          tags=["è§†é¢‘ç”Ÿæˆ"])
async def submit_task(
    request: VideoSubmitRequest,
    auth: bool = Depends(verify_auth)
):
    """æäº¤ç”Ÿæˆä»»åŠ¡"""
    # å‚æ•°éªŒè¯
    if request.image_url is None:
        raise HTTPException(
            status_code=422,
            detail={"status": "Failed", "reason": "éœ€è¦å›¾åƒURLå‚æ•°"}
        )

    # åˆ›å»ºä»»åŠ¡è®°å½•
    task_id = uuid.uuid4().hex
    with app.state.task_lock:
        app.state.tasks[task_id] = {
            "request": request,
            "status": "InQueue",
            "created_at": int(time.time())
        }
        app.state.pending_queue.append(task_id)
  
    return {"requestId": task_id}

@app.post("/video/status",
          response_model=VideoStatusResponse,
          tags=["è§†é¢‘ç”Ÿæˆ"])
async def get_status(
    request: VideoStatusRequest,
    auth: bool = Depends(verify_auth)
):
    """æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€"""
    task = app.state.tasks.get(request.requestId)
    if not task:
        raise HTTPException(
            status_code=404,
            detail={"status": "Failed", "reason": "æ— æ•ˆçš„ä»»åŠ¡ID"}
        )

    # è®¡ç®—é˜Ÿåˆ—ä½ç½®ï¼ˆä»…å½“åœ¨é˜Ÿåˆ—ä¸­æ—¶ï¼‰
    queue_pos = 0
    if task['status'] == "InQueue" and request.requestId in app.state.pending_queue:
        queue_pos = app.state.pending_queue.index(request.requestId) + 1

    response = {
        "status": task['status'],
        "reason": task.get('reason'),
        "queue_position": queue_pos if task['status'] == "InQueue" else None  # éæ’é˜ŸçŠ¶æ€è¿”å›null
    }

    # æˆåŠŸçŠ¶æ€çš„ç‰¹æ®Šå¤„ç†
    if task['status'] == "Succeed":
        response["results"] = {
            "videos": [{"url": task['download_url']}],
            "timings": {
                "inference": task['completed_at'] - task['started_at']
            },
            "seed": task['request'].seed
        }
    # å–æ¶ˆçŠ¶æ€çš„è¡¥å……ä¿¡æ¯
    elif task['status'] == "Cancelled":
        response["reason"] = task.get('reason', "ç”¨æˆ·ä¸»åŠ¨å–æ¶ˆ")  # ç¡®ä¿åŸå› å­—æ®µå­˜åœ¨

    return response

@app.post("/video/cancel",
         response_model=dict,
         tags=["è§†é¢‘ç”Ÿæˆ"])
async def cancel_task(
    request: VideoCancelRequest,
    auth: bool = Depends(verify_auth)
):
    """å–æ¶ˆæ’é˜Ÿä¸­çš„ç”Ÿæˆä»»åŠ¡"""
    task_id = request.requestId
  
    with app.state.task_lock:
        task = app.state.tasks.get(task_id)
      
        # æ£€æŸ¥ä»»åŠ¡æ˜¯å¦å­˜åœ¨
        if not task:
            raise HTTPException(
                status_code=404,
                detail={"status": "Failed", "reason": "æ— æ•ˆçš„ä»»åŠ¡ID"}
            )
          
        current_status = task['status']
      
        # ä»…å…è®¸å–æ¶ˆæ’é˜Ÿä¸­çš„ä»»åŠ¡
        if current_status != "InQueue":
            raise HTTPException(
                status_code=400,
                detail={"status": "Failed", "reason": f"ä»…å…è®¸å–æ¶ˆæ’é˜Ÿä»»åŠ¡ï¼Œå½“å‰çŠ¶æ€: {current_status}"}
            )
      
        # ä»é˜Ÿåˆ—ç§»é™¤
        try:
            app.state.pending_queue.remove(task_id)
        except ValueError:
            pass  # å¯èƒ½å·²è¢«å¤„ç†
      
        # æ›´æ–°ä»»åŠ¡çŠ¶æ€
        task.update({
            "status": "Cancelled",
            "reason": "ç”¨æˆ·ä¸»åŠ¨å–æ¶ˆ",
            "completed_at": int(time.time())
        })
      
    return {"status": "Succeed"}

async def cleanup_files(paths: List[str], delay: int = 3600):
    """å®šæ—¶æ¸…ç†æ–‡ä»¶"""
    await asyncio.sleep(delay)
    for path in paths:
        try:
            if os.path.exists(path):
                os.remove(path)
        except Exception as e:
            print(f"æ¸…ç†å¤±è´¥ {path}: {str(e)}")

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8088)