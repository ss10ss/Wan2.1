import os
import torch
import uuid
import time
import asyncio
from enum import Enum
from threading import Lock
from typing import Optional, Dict, List
from contextlib import asynccontextmanager
from fastapi import FastAPI, HTTPException, status, Depends
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel, Field, field_validator, ValidationError
from diffusers.utils import export_to_video
from diffusers import AutoencoderKLWan, WanPipeline
from diffusers.schedulers.scheduling_unipc_multistep import UniPCMultistepScheduler
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
from fastapi.responses import JSONResponse

# åˆ›å»ºè§†é¢‘å­˜å‚¨ç›®å½•
os.makedirs("generated_videos", exist_ok=True)

# ç”Ÿå‘½å‘¨æœŸç®¡ç†å™¨
@asynccontextmanager
async def lifespan(app: FastAPI):
    """ç®¡ç†åº”ç”¨ç”Ÿå‘½å‘¨æœŸ"""
    # åˆå§‹åŒ–æ¨¡å‹å’Œèµ„æº
    try:
        # åˆå§‹åŒ–è®¤è¯å¯†é’¥
        app.state.valid_api_keys = {
            "å¯†é’¥"
        }

        # åˆå§‹åŒ–è§†é¢‘ç”Ÿæˆæ¨¡å‹
        model_id = "./Wan2.1-T2V-1.3B-Diffusers"
        vae = AutoencoderKLWan.from_pretrained(
            model_id,
            subfolder="vae",
            torch_dtype=torch.float32
        )
      
        scheduler = UniPCMultistepScheduler(
            prediction_type='flow_prediction',
            use_flow_sigmas=True,
            num_train_timesteps=1000,
            flow_shift=3.0
        )
      
        app.state.pipe = WanPipeline.from_pretrained(
            model_id,
            vae=vae,
            torch_dtype=torch.bfloat16
        ).to("cuda")
        app.state.pipe.scheduler = scheduler

        # åˆå§‹åŒ–ä»»åŠ¡ç³»ç»Ÿ
        app.state.tasks: Dict[str, dict] = {}
        app.state.pending_queue: List[str] = []
        app.state.model_lock = Lock()
        app.state.task_lock = Lock()
        app.state.base_url = "ipåœ°å€+ç«¯å£"
        app.state.max_concurrent = 2
        app.state.semaphore = asyncio.Semaphore(app.state.max_concurrent)

        # å¯åŠ¨åå°ä»»åŠ¡å¤„ç†å™¨
        asyncio.create_task(task_processor())
      
        print("âœ… åº”ç”¨åˆå§‹åŒ–å®Œæˆ")
        yield
      
    finally:
        # æ¸…ç†èµ„æº
        if hasattr(app.state, 'pipe'):
            del app.state.pipe
            torch.cuda.empty_cache()
            print("â™»ï¸ å·²é‡Šæ”¾æ¨¡å‹èµ„æº")

# åˆ›å»ºFastAPIåº”ç”¨
app = FastAPI(lifespan=lifespan)
app.mount("/videos", StaticFiles(directory="generated_videos"), name="videos")

# è®¤è¯æ¨¡å—
security = HTTPBearer(auto_error=False)

# ======================
# æ•°æ®æ¨¡å‹--æŸ¥è¯¢å‚æ•°æ¨¡å‹
# ======================
class VideoSubmitRequest(BaseModel):
    model: str = Field(default="Wan2.1-T2V-1.3B",description="ä½¿ç”¨çš„æ¨¡å‹ç‰ˆæœ¬")
    prompt: str = Field(
        ...,
        min_length=10,
        max_length=500,
        description="è§†é¢‘æè¿°æç¤ºè¯ï¼Œ10-500ä¸ªå­—ç¬¦"
    )
    image_size: str = Field(
        ...,
        description="è§†é¢‘åˆ†è¾¨ç‡ï¼Œä»…æ”¯æŒ480x832æˆ–832x480"
    )
    negative_prompt: Optional[str] = Field(
        default=None,
        max_length=500,
        description="æ’é™¤ä¸éœ€è¦çš„å†…å®¹"
    )
    seed: Optional[int] = Field(
        default=None,
        ge=0,
        le=2147483647,
        description="éšæœºæ•°ç§å­ï¼ŒèŒƒå›´0-2147483647"
    )
    num_frames: int = Field(
        default=81,
        ge=24,
        le=120,
        description="è§†é¢‘å¸§æ•°ï¼Œ24-120å¸§"
    )
    guidance_scale: float = Field(
        default=5.0,
        ge=1.0,
        le=20.0,
        description="å¼•å¯¼ç³»æ•°ï¼Œ1.0-20.0"
    )
    infer_steps: int = Field(
        default=50,
        ge=20,
        le=100,
        description="æ¨ç†æ­¥æ•°ï¼Œ20-100æ­¥"
    )

    @field_validator('image_size', mode='before')
    @classmethod
    def validate_image_size(cls, value):
        allowed_sizes = {"480x832", "832x480"}
        if value not in allowed_sizes:
            raise ValueError(f"ä»…æ”¯æŒä»¥ä¸‹åˆ†è¾¨ç‡: {', '.join(allowed_sizes)}")
        return value

class VideoStatusRequest(BaseModel):
    requestId: str = Field(
        ...,
        min_length=32,
        max_length=32,
        description="32ä½ä»»åŠ¡ID"
    )

class VideoSubmitResponse(BaseModel):
    requestId: str

class VideoStatusResponse(BaseModel):
    status: str = Field(..., description="ä»»åŠ¡çŠ¶æ€: Succeed, InQueue, InProgress, Failed,Cancelled")
    reason: Optional[str] = Field(None, description="å¤±è´¥åŸå› ")
    results: Optional[dict] = Field(None, description="ç”Ÿæˆç»“æœ")
    queue_position: Optional[int] = Field(None, description="é˜Ÿåˆ—ä½ç½®")

class VideoCancelRequest(BaseModel):
    requestId: str = Field(
        ...,
        min_length=32,
        max_length=32,
        description="32ä½ä»»åŠ¡ID"
    )

# # è‡ªå®šä¹‰HTTPå¼‚å¸¸å¤„ç†å™¨
# @app.exception_handler(HTTPException)
# async def http_exception_handler(request, exc):
#     return JSONResponse(
#         status_code=exc.status_code,
#         content=exc.detail,  # ç›´æ¥è¿”å›detailå†…å®¹ï¼ˆä¸å†åŒ…è£…åœ¨detailå­—æ®µï¼‰
#         headers=exc.headers
#     )

# ======================
# åå°ä»»åŠ¡å¤„ç†
# ======================
async def task_processor():
    """å¤„ç†ä»»åŠ¡é˜Ÿåˆ—"""
    while True:
        async with app.state.semaphore:
            task_id = await get_next_task()
            if task_id:
                await process_task(task_id)
            else:
                await asyncio.sleep(0.5)

async def get_next_task():
    """è·å–ä¸‹ä¸€ä¸ªå¾…å¤„ç†ä»»åŠ¡"""
    with app.state.task_lock:
        if app.state.pending_queue:
            return app.state.pending_queue.pop(0)
    return None

async def process_task(task_id: str):
    """å¤„ç†å•ä¸ªä»»åŠ¡"""
    task = app.state.tasks.get(task_id)
    if not task:
        return

    try:
        # æ›´æ–°ä»»åŠ¡çŠ¶æ€
        task['status'] = 'InProgress'
        task['started_at'] = int(time.time())

        # æ‰§è¡Œè§†é¢‘ç”Ÿæˆ
        video_path = await generate_video(task['request'], task_id)
      
        # ç”Ÿæˆä¸‹è½½é“¾æ¥
        download_url = f"{app.state.base_url}/videos/{os.path.basename(video_path)}"
      
        # æ›´æ–°ä»»åŠ¡çŠ¶æ€
        task.update({
            'status': 'Succeed',
            'download_url': download_url,
            'completed_at': int(time.time())
        })
      
        # å®‰æ’è‡ªåŠ¨æ¸…ç†
        asyncio.create_task(auto_cleanup(video_path))
    except Exception as e:
        handle_task_error(task, e)

def handle_task_error(task: dict, error: Exception):
    """ç»Ÿä¸€å¤„ç†ä»»åŠ¡é”™è¯¯"""
    error_msg = str(error)
    if isinstance(error, torch.cuda.OutOfMemoryError):
        error_msg = "æ˜¾å­˜ä¸è¶³ï¼Œè¯·é™ä½åˆ†è¾¨ç‡æˆ–å‡å°‘å¸§æ•°"
    elif isinstance(error, ValidationError):
        error_msg = "å‚æ•°æ ¡éªŒå¤±è´¥: " + str(error)
  
    task.update({
        'status': 'Failed',
        'reason': error_msg,
        'completed_at': int(time.time())
    })

# ======================
# è§†é¢‘ç”Ÿæˆæ ¸å¿ƒé€»è¾‘
# ======================
async def generate_video(request: dict, task_id: str) -> str:
    """å¼‚æ­¥æ‰§è¡Œè§†é¢‘ç”Ÿæˆ"""
    loop = asyncio.get_event_loop()
    return await loop.run_in_executor(
        None,
        sync_generate_video,
        request,
        task_id
    )

def sync_generate_video(request: dict, task_id: str) -> str:
    """åŒæ­¥ç”Ÿæˆè§†é¢‘"""
    with app.state.model_lock:
        try:
            generator = None
            if request.get('seed') is not None:
                generator = torch.Generator(device="cuda")
                generator.manual_seed(request['seed'])
                print(f"ğŸ”® ä½¿ç”¨éšæœºç§å­: {request['seed']}")
            
            # æ‰§è¡Œæ¨¡å‹æ¨ç†
            result = app.state.pipe(
                prompt=request['prompt'],
                negative_prompt=request['negative_prompt'],
                height=request['height'],
                width=request['width'],
                num_frames=request['num_frames'],
                guidance_scale=request['guidance_scale'],
                num_inference_steps=request['infer_steps'],
                generator=generator
            )
          
            # å¯¼å‡ºè§†é¢‘æ–‡ä»¶
            video_id = uuid.uuid4().hex
            output_path = f"generated_videos/{video_id}.mp4"
            export_to_video(result.frames[0], output_path, fps=16)
          
            return output_path
        except Exception as e:
            raise RuntimeError(f"è§†é¢‘ç”Ÿæˆå¤±è´¥: {str(e)}") from e

# ======================
# APIç«¯ç‚¹
# ======================
async def verify_auth(credentials: HTTPAuthorizationCredentials = Depends(security)):
    """è®¤è¯éªŒè¯"""
    if not credentials:
        raise HTTPException(
            status_code=401,
            detail={"status": "Failed", "reason": "ç¼ºå°‘è®¤è¯å¤´"},
            headers={"WWW-Authenticate": "Bearer"}
        )
    if credentials.scheme != "Bearer":
        raise HTTPException(
            status_code=401,
            detail={"status": "Failed", "reason": "æ— æ•ˆçš„è®¤è¯æ–¹æ¡ˆ"},
            headers={"WWW-Authenticate": "Bearer"}
        )
    if credentials.credentials not in app.state.valid_api_keys:
        raise HTTPException(
            status_code=401,
            detail={"status": "Failed", "reason": "æ— æ•ˆçš„APIå¯†é’¥"},
            headers={"WWW-Authenticate": "Bearer"}
        )
    return True

@app.post("/video/submit",
          response_model=VideoSubmitResponse,
          status_code=status.HTTP_202_ACCEPTED,
          tags=["è§†é¢‘ç”Ÿæˆ"],
          summary="æäº¤è§†é¢‘ç”Ÿæˆè¯·æ±‚")
async def submit_video_task(
    request: VideoSubmitRequest,
    auth: bool = Depends(verify_auth)
):
    """æäº¤æ–°çš„è§†é¢‘ç”Ÿæˆä»»åŠ¡"""
    try:
        # è§£æåˆ†è¾¨ç‡å‚æ•°
        width, height = map(int, request.image_size.split('x'))
      
        # åˆ›å»ºä»»åŠ¡è®°å½•
        task_id = uuid.uuid4().hex
        task_data = {
            'request': {
                'prompt': request.prompt,
                'negative_prompt': request.negative_prompt,
                'width': width,
                'height': height,
                'num_frames': request.num_frames,
                'guidance_scale': request.guidance_scale,
                'infer_steps': request.infer_steps,
                'seed': request.seed
            },
            'status': 'InQueue',
            'created_at': int(time.time())
        }
      
        # åŠ å…¥ä»»åŠ¡é˜Ÿåˆ—
        with app.state.task_lock:
            app.state.tasks[task_id] = task_data
            app.state.pending_queue.append(task_id)
      
        return {"requestId": task_id}
  
    except ValidationError as e:
        raise HTTPException(
            status_code=422,
            detail={"status": "Failed", "reason": str(e)}
        )

@app.post("/video/status",
          response_model=VideoStatusResponse,
          tags=["è§†é¢‘ç”Ÿæˆ"],
          summary="æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€")
async def get_video_status(
    request: VideoStatusRequest,
    auth: bool = Depends(verify_auth)
):
    """æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€"""
    task = app.state.tasks.get(request.requestId)
    if not task:
        raise HTTPException(
            status_code=404,
            detail={"status": "Failed", "reason": "æ— æ•ˆçš„ä»»åŠ¡ID"}
        )

    # è®¡ç®—é˜Ÿåˆ—ä½ç½®ï¼ˆä»…å½“åœ¨é˜Ÿåˆ—ä¸­æ—¶ï¼‰
    queue_pos = 0
    if task['status'] == "InQueue" and request.requestId in app.state.pending_queue:
        queue_pos = app.state.pending_queue.index(request.requestId) + 1

    response = {
        "status": task['status'],
        "reason": task.get('reason'),
        "queue_position": queue_pos if task['status'] == "InQueue" else None  # éæ’é˜ŸçŠ¶æ€è¿”å›null
    }

    # æˆåŠŸçŠ¶æ€çš„ç‰¹æ®Šå¤„ç†
    if task['status'] == "Succeed":
        response["results"] = {
            "videos": [{"url": task['download_url']}],
            "timings": {
                "inference": task['completed_at'] - task['started_at']
            },
            "seed": task['request']['seed']
        }
    # å–æ¶ˆçŠ¶æ€çš„è¡¥å……ä¿¡æ¯
    elif task['status'] == "Cancelled":
        response["reason"] = task.get('reason', "ç”¨æˆ·ä¸»åŠ¨å–æ¶ˆ")  # ç¡®ä¿åŸå› å­—æ®µå­˜åœ¨

    return response


@app.post("/video/cancel",
         response_model=dict,
         tags=["è§†é¢‘ç”Ÿæˆ"])
async def cancel_task(
    request: VideoCancelRequest,
    auth: bool = Depends(verify_auth)
):
    """å–æ¶ˆæ’é˜Ÿä¸­çš„ç”Ÿæˆä»»åŠ¡"""
    task_id = request.requestId
  
    with app.state.task_lock:
        task = app.state.tasks.get(task_id)
      
        # æ£€æŸ¥ä»»åŠ¡æ˜¯å¦å­˜åœ¨
        if not task:
            raise HTTPException(
                status_code=404,
                detail={"status": "Failed", "reason": "æ— æ•ˆçš„ä»»åŠ¡ID"}
            )
          
        current_status = task['status']
      
        # ä»…å…è®¸å–æ¶ˆæ’é˜Ÿä¸­çš„ä»»åŠ¡
        if current_status != "InQueue":
            raise HTTPException(
                status_code=400,
                detail={"status": "Failed", "reason": f"ä»…å…è®¸å–æ¶ˆæ’é˜Ÿä»»åŠ¡ï¼Œå½“å‰çŠ¶æ€: {current_status}"}
            )
      
        # ä»é˜Ÿåˆ—ç§»é™¤
        try:
            app.state.pending_queue.remove(task_id)
        except ValueError:
            pass  # å¯èƒ½å·²è¢«å¤„ç†
      
        # æ›´æ–°ä»»åŠ¡çŠ¶æ€
        task.update({
            "status": "Cancelled",
            "reason": "ç”¨æˆ·ä¸»åŠ¨å–æ¶ˆ",
            "completed_at": int(time.time())
        })
      
    return {"status": "Succeed"}


# ======================
# å·¥å…·å‡½æ•°
# ======================
async def auto_cleanup(file_path: str, delay: int = 3600):
    """è‡ªåŠ¨æ¸…ç†ç”Ÿæˆçš„è§†é¢‘æ–‡ä»¶"""
    await asyncio.sleep(delay)
    try:
        if os.path.exists(file_path):
            os.remove(file_path)
            print(f"å·²æ¸…ç†æ–‡ä»¶: {file_path}")
    except Exception as e:
        print(f"æ–‡ä»¶æ¸…ç†å¤±è´¥: {str(e)}")

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8088)